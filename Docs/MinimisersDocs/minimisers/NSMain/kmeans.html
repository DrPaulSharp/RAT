<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of kmeans</title>
  <meta name="keywords" content="kmeans">
  <meta name="description" content="KMEANS K-means clustering.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../m2html.css">
  <script type="text/javascript">
    if (top.frames.length == 0) { top.location = "../../index.html"; };
  </script>
</head>
<body>
<a name="_top"></a>
<!-- ../menu.html minimisers --><!-- menu.html NSMain -->
<h1>kmeans
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>KMEANS K-means clustering.</strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="box"><strong>function [idx, C, sumD, D] = kmeans(X, k, varargin) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre class="comment">KMEANS K-means clustering.
   IDX = KMEANS(X, K) partitions the points in the N-by-P data matrix
   X into K clusters.  This partition minimizes the sum, over all
   clusters, of the within-cluster sums of point-to-cluster-centroid
   distances.  Rows of X correspond to points, columns correspond to
   variables.  KMEANS returns an N-by-1 vector IDX containing the
   cluster indices of each point.  By default, KMEANS uses squared
   Euclidean distances.

   [IDX, C] = KMEANS(X, K) returns the K cluster centroid locations in
   the K-by-P matrix C.

   [IDX, C, SUMD] = KMEANS(X, K) returns the within-cluster sums of
   point-to-centroid distances in the 1-by-K vector sumD.

   [IDX, C, SUMD, D] = KMEANS(X, K) returns distances from each point
   to every centroid in the N-by-K matrix D.

   [ ... ] = KMEANS(..., 'PARAM1',val1, 'PARAM2',val2, ...) allows you to
   specify optional parameter name/value pairs to control the iterative
   algorithm used by KMEANS.  Parameters are:

   'Distance' - Distance measure, in P-dimensional space, that KMEANS
      should minimize with respect to.  Choices are:
            {'sqEuclidean'} - Squared Euclidean distance
             'cityblock'    - Sum of absolute differences, a.k.a. L1
             'cosine'       - One minus the cosine of the included angle
                              between points (treated as vectors)
             'correlation'  - One minus the sample correlation between
                              points (treated as sequences of values)
             'Hamming'      - Percentage of bits that differ (only
                              suitable for binary data)

   'Start' - Method used to choose initial cluster centroid positions,
      sometimes known as &quot;seeds&quot;.  Choices are:
                 {'sample'} - Select K observations from X at random
                  'uniform' - Select K points uniformly at random from
                              the range of X.  Not valid for Hamming distance.
                  'cluster' - Perform preliminary clustering phase on
                              random 10% subsample of X.  This preliminary
                              phase is itself initialized using 'sample'.
                  matrix    - A K-by-P matrix of starting locations.  In
                              this case, you can pass in [] for K, and
                              KMEANS infers K from the first dimension of
                              the matrix.  You can also supply a 3D array,
                              implying a value for 'Replicates'
                              from the array's third dimension.

   'Replicates' - Number of times to repeat the clustering, each with a
      new set of initial centroids [ positive integer | {1}]

   'Maxiter' - The maximum number of iterations [ positive integer | {100}]

   'EmptyAction' - Action to take if a cluster loses all of its member
      observations.  Choices are:
               {'error'}    - Treat an empty cluster as an error
                'drop'      - Remove any clusters that become empty, and
                              set corresponding values in C and D to NaN.
                'singleton' - Create a new cluster consisting of the one
                              observation furthest from its centroid.

   'Display' - Display level [ 'off' | {'notify'} | 'final' | 'iter' ]

   Example:

       X = [randn(20,2)+ones(20,2); randn(20,2)-ones(20,2)];
       [cidx, ctrs] = kmeans(X, 2, 'dist','city', 'rep',5, 'disp','final');
       plot(X(cidx==1,1),X(cidx==1,2),'r.', ...
            X(cidx==2,1),X(cidx==2,2),'b.', ctrs(:,1),ctrs(:,2),'kx');

   See also LINKAGE, CLUSTERDATA, SILHOUETTE.</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="kmeans.html" class="code" title="function [idx, C, sumD, D] = kmeans(X, k, varargin)">kmeans</a>	KMEANS K-means clustering.</li><li><a href="randsample.html" class="code" title="function y = randsample(n, k)">randsample</a>	RANDSAMPLE Random sampling, without replacement</li><li><a href="statgetargs.html" class="code" title="function [emsg,varargout]=statgetargs(pnames,dflts,varargin)">statgetargs</a>	STATGETARGS Process parameter name/value pairs for statistics functions</li></ul>
This function is called by:
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="kmeans.html" class="code" title="function [idx, C, sumD, D] = kmeans(X, k, varargin)">kmeans</a>	KMEANS K-means clustering.</li><li><a href="split_ellipsoid.html" class="code" title="function [u1, u2, VE1, VE2, nosplit] = split_ellipsoid(u, VS)">split_ellipsoid</a>	function [u1, u2, VE1, VE2, nosplit] = split_ellipsiod(u, VS)</li></ul>
<!-- crossreference -->

<h2><a name="_subfunctions"></a>SUBFUNCTIONS <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<ul style="list-style-image:url(../../matlabicon.gif)">
<li><a href="#_sub1" class="code">function D = distfun(X, C, dist, iter)</a></li><li><a href="#_sub2" class="code">function [centroids, counts] = gcentroids(X, index, clusts, dist, Xsort, Xord)</a></li></ul>

<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [idx, C, sumD, D] = kmeans(X, k, varargin)</a>
0002 <span class="comment">%KMEANS K-means clustering.</span>
0003 <span class="comment">%   IDX = KMEANS(X, K) partitions the points in the N-by-P data matrix</span>
0004 <span class="comment">%   X into K clusters.  This partition minimizes the sum, over all</span>
0005 <span class="comment">%   clusters, of the within-cluster sums of point-to-cluster-centroid</span>
0006 <span class="comment">%   distances.  Rows of X correspond to points, columns correspond to</span>
0007 <span class="comment">%   variables.  KMEANS returns an N-by-1 vector IDX containing the</span>
0008 <span class="comment">%   cluster indices of each point.  By default, KMEANS uses squared</span>
0009 <span class="comment">%   Euclidean distances.</span>
0010 <span class="comment">%</span>
0011 <span class="comment">%   [IDX, C] = KMEANS(X, K) returns the K cluster centroid locations in</span>
0012 <span class="comment">%   the K-by-P matrix C.</span>
0013 <span class="comment">%</span>
0014 <span class="comment">%   [IDX, C, SUMD] = KMEANS(X, K) returns the within-cluster sums of</span>
0015 <span class="comment">%   point-to-centroid distances in the 1-by-K vector sumD.</span>
0016 <span class="comment">%</span>
0017 <span class="comment">%   [IDX, C, SUMD, D] = KMEANS(X, K) returns distances from each point</span>
0018 <span class="comment">%   to every centroid in the N-by-K matrix D.</span>
0019 <span class="comment">%</span>
0020 <span class="comment">%   [ ... ] = KMEANS(..., 'PARAM1',val1, 'PARAM2',val2, ...) allows you to</span>
0021 <span class="comment">%   specify optional parameter name/value pairs to control the iterative</span>
0022 <span class="comment">%   algorithm used by KMEANS.  Parameters are:</span>
0023 <span class="comment">%</span>
0024 <span class="comment">%   'Distance' - Distance measure, in P-dimensional space, that KMEANS</span>
0025 <span class="comment">%      should minimize with respect to.  Choices are:</span>
0026 <span class="comment">%            {'sqEuclidean'} - Squared Euclidean distance</span>
0027 <span class="comment">%             'cityblock'    - Sum of absolute differences, a.k.a. L1</span>
0028 <span class="comment">%             'cosine'       - One minus the cosine of the included angle</span>
0029 <span class="comment">%                              between points (treated as vectors)</span>
0030 <span class="comment">%             'correlation'  - One minus the sample correlation between</span>
0031 <span class="comment">%                              points (treated as sequences of values)</span>
0032 <span class="comment">%             'Hamming'      - Percentage of bits that differ (only</span>
0033 <span class="comment">%                              suitable for binary data)</span>
0034 <span class="comment">%</span>
0035 <span class="comment">%   'Start' - Method used to choose initial cluster centroid positions,</span>
0036 <span class="comment">%      sometimes known as &quot;seeds&quot;.  Choices are:</span>
0037 <span class="comment">%                 {'sample'} - Select K observations from X at random</span>
0038 <span class="comment">%                  'uniform' - Select K points uniformly at random from</span>
0039 <span class="comment">%                              the range of X.  Not valid for Hamming distance.</span>
0040 <span class="comment">%                  'cluster' - Perform preliminary clustering phase on</span>
0041 <span class="comment">%                              random 10% subsample of X.  This preliminary</span>
0042 <span class="comment">%                              phase is itself initialized using 'sample'.</span>
0043 <span class="comment">%                  matrix    - A K-by-P matrix of starting locations.  In</span>
0044 <span class="comment">%                              this case, you can pass in [] for K, and</span>
0045 <span class="comment">%                              KMEANS infers K from the first dimension of</span>
0046 <span class="comment">%                              the matrix.  You can also supply a 3D array,</span>
0047 <span class="comment">%                              implying a value for 'Replicates'</span>
0048 <span class="comment">%                              from the array's third dimension.</span>
0049 <span class="comment">%</span>
0050 <span class="comment">%   'Replicates' - Number of times to repeat the clustering, each with a</span>
0051 <span class="comment">%      new set of initial centroids [ positive integer | {1}]</span>
0052 <span class="comment">%</span>
0053 <span class="comment">%   'Maxiter' - The maximum number of iterations [ positive integer | {100}]</span>
0054 <span class="comment">%</span>
0055 <span class="comment">%   'EmptyAction' - Action to take if a cluster loses all of its member</span>
0056 <span class="comment">%      observations.  Choices are:</span>
0057 <span class="comment">%               {'error'}    - Treat an empty cluster as an error</span>
0058 <span class="comment">%                'drop'      - Remove any clusters that become empty, and</span>
0059 <span class="comment">%                              set corresponding values in C and D to NaN.</span>
0060 <span class="comment">%                'singleton' - Create a new cluster consisting of the one</span>
0061 <span class="comment">%                              observation furthest from its centroid.</span>
0062 <span class="comment">%</span>
0063 <span class="comment">%   'Display' - Display level [ 'off' | {'notify'} | 'final' | 'iter' ]</span>
0064 <span class="comment">%</span>
0065 <span class="comment">%   Example:</span>
0066 <span class="comment">%</span>
0067 <span class="comment">%       X = [randn(20,2)+ones(20,2); randn(20,2)-ones(20,2)];</span>
0068 <span class="comment">%       [cidx, ctrs] = kmeans(X, 2, 'dist','city', 'rep',5, 'disp','final');</span>
0069 <span class="comment">%       plot(X(cidx==1,1),X(cidx==1,2),'r.', ...</span>
0070 <span class="comment">%            X(cidx==2,1),X(cidx==2,2),'b.', ctrs(:,1),ctrs(:,2),'kx');</span>
0071 <span class="comment">%</span>
0072 <span class="comment">%   See also LINKAGE, CLUSTERDATA, SILHOUETTE.</span>
0073 
0074 <span class="comment">%   KMEANS uses a two-phase iterative algorithm to minimize the sum of</span>
0075 <span class="comment">%   point-to-centroid distances, summed over all K clusters.  The first</span>
0076 <span class="comment">%   phase uses what the literature often describes as &quot;batch&quot; updates,</span>
0077 <span class="comment">%   where each iteration consists of reassigning points to their nearest</span>
0078 <span class="comment">%   cluster centroid, all at once, followed by recalculation of cluster</span>
0079 <span class="comment">%   centroids. This phase may be thought of as providing a fast but</span>
0080 <span class="comment">%   potentially only approximate solution as a starting point for the</span>
0081 <span class="comment">%   second phase.  The second phase uses what the literature often</span>
0082 <span class="comment">%   describes as &quot;on-line&quot; updates, where points are individually</span>
0083 <span class="comment">%   reassigned if doing so will reduce the sum of distances, and cluster</span>
0084 <span class="comment">%   centroids are recomputed after each reassignment.  Each iteration</span>
0085 <span class="comment">%   during this second phase consists of one pass though all the points.</span>
0086 <span class="comment">%   KMEANS can converge to a local optimum, which in this case is a</span>
0087 <span class="comment">%   partition of points in which moving any single point to a different</span>
0088 <span class="comment">%   cluster increases the total sum of distances.  This problem can only be</span>
0089 <span class="comment">%   solved by a clever (or lucky, or exhaustive) choice of starting points.</span>
0090 <span class="comment">%</span>
0091 <span class="comment">% References:</span>
0092 <span class="comment">%</span>
0093 <span class="comment">%   [1] Seber, G.A.F., Multivariate Observations, Wiley, New York, 1984.</span>
0094 <span class="comment">%   [2] Spath, H. (1985) Cluster Dissection and Analysis: Theory, FORTRAN</span>
0095 <span class="comment">%       Programs, Examples, translated by J. Goldschmidt, Halsted Press,</span>
0096 <span class="comment">%       New York, 226 pp.</span>
0097 
0098 <span class="comment">%   Copyright 1993-2000 The MathWorks, Inc.</span>
0099 <span class="comment">%   $Revision: 1.4 $  $Date: 2002/05/30 16:13:31 $</span>
0100 
0101 <span class="comment">%</span>
0102 <span class="keyword">if</span> nargin &lt; 2
0103     error(<span class="string">'At least two input arguments required.'</span>);
0104 <span class="keyword">end</span>
0105 
0106 <span class="comment">% n points in p dimensional space</span>
0107 [n, p] = size(X);
0108 Xsort = []; 
0109 Xord = []; 
0110 changed = zeros(k,1); 
0111 normC = zeros(k,1);
0112 
0113 pnames = {   <span class="string">'distance'</span>  <span class="string">'start'</span> <span class="string">'replicates'</span> <span class="string">'maxiter'</span> <span class="string">'emptyaction'</span> <span class="string">'display'</span>};
0114 dflts =  {<span class="string">'sqeuclidean'</span> <span class="string">'sample'</span>          []       100        <span class="string">'error'</span>  <span class="string">'notify'</span>};
0115 [errmsg,distance,start,reps,maxit,emptyact,display] <span class="keyword">...</span>
0116                        = <a href="statgetargs.html" class="code" title="function [emsg,varargout]=statgetargs(pnames,dflts,varargin)">statgetargs</a>(pnames, dflts, varargin{:});
0117 error(errmsg);
0118 
0119 <span class="keyword">if</span> ischar(distance)
0120     distNames = {<span class="string">'sqeuclidean'</span>,<span class="string">'cityblock'</span>,<span class="string">'cosine'</span>,<span class="string">'correlation'</span>,<span class="string">'hamming'</span>};
0121     i = find(strncmp(lower(distance), distNames,length(lower(distance))));
0122     <span class="keyword">if</span> length(i) &gt; 1
0123         error(sprintf(<span class="string">'Ambiguous ''distance'' parameter value:  %s.'</span>, distance));
0124     <span class="keyword">elseif</span> isempty(i)
0125         error(sprintf(<span class="string">'Unknown ''distance'' parameter value:  %s.'</span>, distance));
0126     <span class="keyword">end</span>
0127     distance = distNames{i};
0128     <span class="keyword">switch</span> distance 
0129     <span class="keyword">case</span> <span class="string">'cityblock'</span>
0130         [Xsort,Xord] = sort(X,1);
0131     <span class="keyword">case</span> <span class="string">'cosine'</span>
0132         Xnorm = sqrt(sum(X.^2, 2));
0133         <span class="keyword">if</span> any(min(Xnorm) &lt;= eps * max(Xnorm))
0134             error([<span class="string">'Some points have small relative magnitudes, making them '</span>, <span class="keyword">...</span>
0135                    <span class="string">'effectively zero.\nEither remove those points, or choose a '</span>, <span class="keyword">...</span>
0136                    <span class="string">'distance other than ''cosine''.'</span>], []);
0137         <span class="keyword">end</span>
0138         X = X ./ Xnorm(:,ones(1,p));
0139     <span class="keyword">case</span> <span class="string">'correlation'</span>
0140         X = X - repmat(mean(X,2),1,p);
0141         Xnorm = sqrt(sum(X.^2, 2));
0142         <span class="keyword">if</span> any(min(Xnorm) &lt;= eps * max(Xnorm))
0143             error([<span class="string">'Some points have small relative standard deviations, making them '</span>, <span class="keyword">...</span>
0144                    <span class="string">'effectively constant.\nEither remove those points, or choose a '</span>, <span class="keyword">...</span>
0145                    <span class="string">'distance other than ''correlation''.'</span>], []);
0146         <span class="keyword">end</span>
0147         X = X ./ Xnorm(:,ones(1,p));
0148     <span class="keyword">case</span> <span class="string">'hamming'</span>
0149         <span class="keyword">if</span> ~all(ismember(X(:),[0 1]))
0150             error(<span class="string">'Non-binary data cannot be clustered using Hamming distance.'</span>);
0151         <span class="keyword">end</span>
0152     <span class="keyword">end</span>
0153 <span class="keyword">else</span>
0154     error(<span class="string">'The ''distance'' parameter value must be a string.'</span>);
0155 <span class="keyword">end</span>
0156 
0157 <span class="keyword">if</span> ischar(start)
0158     startNames = {<span class="string">'uniform'</span>,<span class="string">'sample'</span>,<span class="string">'cluster'</span>};
0159     i = strmatch(lower(start), startNames);
0160     <span class="keyword">if</span> length(i) &gt; 1
0161         error(sprintf(<span class="string">'Ambiguous ''start'' parameter value:  %s.'</span>, start));
0162     <span class="keyword">elseif</span> isempty(i)
0163         error(sprintf(<span class="string">'Unknown ''start'' parameter value:  %s.'</span>, start));
0164     <span class="keyword">elseif</span> isempty(k)
0165         error(<span class="string">'You must specify the number of clusters, K.'</span>);
0166     <span class="keyword">end</span>
0167     start = startNames{i};
0168     <span class="keyword">if</span> strcmp(start, <span class="string">'uniform'</span>)
0169         <span class="keyword">if</span> strcmp(distance, <span class="string">'hamming'</span>)
0170             error(<span class="string">'Hamming distance cannot be initialized with uniform random values.'</span>);
0171         <span class="keyword">end</span>
0172         Xmins = min(X,1);
0173         Xmaxs = max(X,1);
0174     <span class="keyword">end</span>
0175 <span class="keyword">elseif</span> isnumeric(start)
0176     CC = start;
0177     start = <span class="string">'numeric'</span>;
0178     <span class="keyword">if</span> isempty(k)
0179         k = size(CC,1);
0180     <span class="keyword">elseif</span> k ~= size(CC,1);
0181         error(<span class="string">'The ''start'' matrix must have K rows.'</span>);
0182     <span class="keyword">elseif</span> size(CC,2) ~= p
0183         error(<span class="string">'The ''start'' matrix must have the same number of columns as X.'</span>);
0184     <span class="keyword">end</span>
0185     <span class="keyword">if</span> isempty(reps)
0186         reps = size(CC,3);
0187     <span class="keyword">elseif</span> reps ~= size(CC,3);
0188         error(<span class="string">'The third dimension of the ''start'' array must match the ''replicates'' parameter value.'</span>);
0189     <span class="keyword">end</span>
0190     
0191     <span class="comment">% Need to center explicit starting points for 'correlation'. (Re)normalization</span>
0192     <span class="comment">% for 'cosine'/'correlation' is done at each iteration.</span>
0193     <span class="keyword">if</span> isequal(distance, <span class="string">'correlation'</span>)
0194         CC = CC - repmat(mean(CC,2),[1,p,1]);
0195     <span class="keyword">end</span>
0196 <span class="keyword">else</span>
0197     error(<span class="string">'The ''start'' parameter value must be a string or a numeric matrix or array.'</span>);
0198 <span class="keyword">end</span>
0199 
0200 <span class="keyword">if</span> ischar(emptyact)
0201     emptyactNames = {<span class="string">'error'</span>,<span class="string">'drop'</span>,<span class="string">'singleton'</span>};
0202     i = find(strncmp(lower(emptyact),emptyactNames,length(emptyactNames)));
0203     <span class="keyword">if</span> length(i) &gt; 1
0204         error(sprintf(<span class="string">'Ambiguous ''emptyaction'' parameter value:  %s.'</span>, emptyact));
0205     <span class="keyword">elseif</span> isempty(i)
0206         error(sprintf(<span class="string">'Unknown ''emptyaction'' parameter value:  %s.'</span>, emptyact));
0207     <span class="keyword">end</span>
0208     emptyact = emptyactNames{i};
0209 <span class="keyword">else</span>
0210     error(<span class="string">'The ''emptyaction'' parameter value must be a string.'</span>);
0211 <span class="keyword">end</span>
0212 
0213 <span class="keyword">if</span> ischar(display)
0214     i = strncmp(lower(display), char({<span class="string">'off'</span>,<span class="string">'notify'</span>,<span class="string">'final'</span>,<span class="string">'iter'</span>}),4);
0215     <span class="keyword">if</span> length(i) &gt; 1
0216         error(sprintf(<span class="string">'Ambiguous ''display'' parameter value:  %s.'</span>, display));
0217     <span class="keyword">elseif</span> isempty(i)
0218         error(sprintf(<span class="string">'Unknown ''display'' parameter value:  %s.'</span>, display));
0219     <span class="keyword">end</span>
0220     display = i-1;
0221 <span class="keyword">else</span>
0222     error(<span class="string">'The ''display'' parameter value must be a string.'</span>);
0223 <span class="keyword">end</span>
0224 
0225 <span class="keyword">if</span> k == 1
0226     error(<span class="string">'The number of clusters must be greater than 1.'</span>);
0227 <span class="keyword">elseif</span> n &lt; k
0228     error(<span class="string">'X must have more rows than the number of clusters.'</span>);
0229 <span class="keyword">end</span>
0230 
0231 <span class="comment">% Assume one replicate</span>
0232 <span class="keyword">if</span> isempty(reps)
0233     reps = 1;
0234 <span class="keyword">end</span>
0235 
0236 <span class="comment">%</span>
0237 <span class="comment">% Done with input argument processing, begin clustering</span>
0238 <span class="comment">%</span>
0239 
0240 dispfmt = <span class="string">'%6d\t%6d\t%8d\t%12g'</span>;
0241 D = repmat(NaN,n,k);   <span class="comment">% point-to-cluster distances</span>
0242 Del = repmat(NaN,n,k); <span class="comment">% reassignment criterion</span>
0243 m = zeros(k,1);
0244 
0245 totsumDBest = Inf;
0246 <span class="keyword">for</span> rep = 1:reps
0247     <span class="keyword">switch</span> start
0248     <span class="keyword">case</span> <span class="string">'uniform'</span>
0249         C = unifrnd(Xmins(ones(k,1),:), Xmaxs(ones(k,1),:));
0250         <span class="comment">% For 'cosine' and 'correlation', these are uniform inside a subset</span>
0251         <span class="comment">% of the unit hypersphere.  Still need to center them for</span>
0252         <span class="comment">% 'correlation'.  (Re)normalization for 'cosine'/'correlation' is</span>
0253         <span class="comment">% done at each iteration.</span>
0254         <span class="keyword">if</span> isequal(distance, <span class="string">'correlation'</span>)
0255             C = C - repmat(mean(C,2),1,p);
0256         <span class="keyword">end</span>
0257     <span class="keyword">case</span> <span class="string">'sample'</span>
0258         C = double(X(<a href="randsample.html" class="code" title="function y = randsample(n, k)">randsample</a>(n,k),:)); <span class="comment">% X may be logical</span>
0259     <span class="keyword">case</span> <span class="string">'cluster'</span>
0260         Xsubset = X(<a href="randsample.html" class="code" title="function y = randsample(n, k)">randsample</a>(n,floor(.1*n)),:);
0261         [dum, C] = <a href="kmeans.html" class="code" title="function [idx, C, sumD, D] = kmeans(X, k, varargin)">kmeans</a>(Xsubset, k, varargin{:}, <span class="string">'start'</span>,<span class="string">'sample'</span>, <span class="string">'replicates'</span>,1);
0262     <span class="keyword">case</span> <span class="string">'numeric'</span>
0263         C = CC(:,:,rep);
0264     <span class="keyword">end</span>    
0265     changed = 1:k; <span class="comment">% everything is newly assigned</span>
0266     idx = zeros(n,1);
0267     totsumD = Inf;
0268     
0269     <span class="keyword">if</span> display &gt; 2 <span class="comment">% 'iter'</span>
0270         disp(sprintf(<span class="string">'  iter\t phase\t     num\t         sum'</span>));
0271     <span class="keyword">end</span>
0272     
0273     <span class="comment">%</span>
0274     <span class="comment">% Begin phase one:  batch reassignments</span>
0275     <span class="comment">%</span>
0276     
0277     converged = false;
0278     iter = 0;
0279     <span class="keyword">while</span> true
0280         <span class="comment">% Compute the distance from every point to each cluster centroid</span>
0281         D(:,changed) = <a href="#_sub1" class="code" title="subfunction D = distfun(X, C, dist, iter)">distfun</a>(X, C(changed,:), distance, iter);
0282         
0283         <span class="comment">% Compute the total sum of distances for the current configuration.</span>
0284         <span class="comment">% Can't do it first time through, there's no configuration yet.</span>
0285         <span class="keyword">if</span> iter &gt; 0
0286             totsumD = sum(D((idx-1)*n + (1:n)'));
0287             <span class="comment">% Test for a cycle: if objective is not decreased, back out</span>
0288             <span class="comment">% the last step and move on to the single update phase</span>
0289             <span class="keyword">if</span> prevtotsumD &lt;= totsumD
0290                 idx = previdx;
0291                 [C(changed,:), m(changed)] = <a href="#_sub2" class="code" title="subfunction [centroids, counts] = gcentroids(X, index, clusts, dist, Xsort, Xord)">gcentroids</a>(X, idx, changed, distance, Xsort, Xord);
0292                 iter = iter - 1;
0293                 <span class="keyword">break</span>;
0294             <span class="keyword">end</span>
0295             <span class="keyword">if</span> display &gt; 2 <span class="comment">% 'iter'</span>
0296                 disp(sprintf(dispfmt,iter,1,length(moved),totsumD));
0297             <span class="keyword">end</span>
0298             <span class="keyword">if</span> iter &gt;= maxit, <span class="keyword">break</span>; <span class="keyword">end</span>
0299         <span class="keyword">end</span>
0300 
0301         <span class="comment">% Determine closest cluster for each point and reassign points to clusters</span>
0302         previdx = idx;
0303         prevtotsumD = totsumD;
0304         [d, nidx] = min(D, [], 2);
0305 
0306         <span class="keyword">if</span> iter == 0
0307             <span class="comment">% Every point moved, every cluster will need an update</span>
0308             moved = 1:n;
0309             idx = nidx;
0310             changed = 1:k;
0311         <span class="keyword">else</span>
0312             <span class="comment">% Determine which points moved</span>
0313             moved = find(nidx ~= previdx);
0314             <span class="keyword">if</span> length(moved) &gt; 0
0315                 <span class="comment">% Resolve ties in favor of not moving</span>
0316                 moved = moved(D((previdx(moved)-1)*n + moved) &gt; d(moved));
0317             <span class="keyword">end</span>
0318             <span class="keyword">if</span> length(moved) == 0
0319                 <span class="keyword">break</span>;
0320             <span class="keyword">end</span>
0321             idx(moved) = nidx(moved);
0322 
0323             <span class="comment">% Find clusters that gained or lost members</span>
0324             changed = unique([idx(moved); previdx(moved)])';
0325         <span class="keyword">end</span>
0326 
0327         <span class="comment">% Calculate the new cluster centroids and counts.</span>
0328         [C(changed,:), m(changed)] = <a href="#_sub2" class="code" title="subfunction [centroids, counts] = gcentroids(X, index, clusts, dist, Xsort, Xord)">gcentroids</a>(X, idx, changed, distance, Xsort, Xord);
0329         iter = iter + 1;
0330         
0331         <span class="comment">% Deal with clusters that have just lost all their members</span>
0332         empties = changed(m(changed) == 0);
0333         <span class="keyword">if</span> ~isempty(empties)
0334             <span class="keyword">switch</span> emptyact
0335             <span class="keyword">case</span> <span class="string">'error'</span>
0336                 error(sprintf(<span class="string">'Empty cluster created at iteration %d.'</span>,iter));
0337             <span class="keyword">case</span> <span class="string">'drop'</span>
0338                 <span class="comment">% Remove the empty cluster from any further processing</span>
0339                 D(:,empties) = NaN;
0340                 changed = changed(m(changed) &gt; 0);
0341                 <span class="keyword">if</span> display &gt; 0
0342                     warning(sprintf(<span class="string">'Empty cluster created at iteration %d.'</span>,iter));
0343                 <span class="keyword">end</span>
0344             <span class="keyword">case</span> <span class="string">'singleton'</span>
0345                 <span class="keyword">if</span> display &gt; 0
0346                     warning(sprintf(<span class="string">'Empty cluster created at iteration %d.'</span>,iter));
0347                 <span class="keyword">end</span>
0348                 
0349                 <span class="keyword">for</span> i = empties
0350                     <span class="comment">% Find the point furthest away from its current cluster.</span>
0351                     <span class="comment">% Take that point out of its cluster and use it to create</span>
0352                     <span class="comment">% a new singleton cluster to replace the empty one.</span>
0353                     [dlarge, lonely] = max(d);
0354                     from = idx(lonely); <span class="comment">% taking from this cluster</span>
0355                     C(i,:) = X(lonely,:);
0356                     m(i) = 1;
0357                     idx(lonely) = i;
0358                     d(lonely) = 0;
0359                     
0360                     <span class="comment">% Update clusters from which points are taken</span>
0361                     [C(from,:), m(from)] = <a href="#_sub2" class="code" title="subfunction [centroids, counts] = gcentroids(X, index, clusts, dist, Xsort, Xord)">gcentroids</a>(X, idx, from, distance, Xsort, Xord);
0362                     changed = unique([changed from]);
0363                 <span class="keyword">end</span>
0364             <span class="keyword">end</span>
0365         <span class="keyword">end</span>
0366     <span class="keyword">end</span> <span class="comment">% phase one</span>
0367 
0368     <span class="comment">% Initialize some cluster information prior to phase two</span>
0369     <span class="keyword">switch</span> distance
0370     <span class="keyword">case</span> <span class="string">'cityblock'</span>
0371         Xmid = zeros([k,p,2]);
0372         <span class="keyword">for</span> i = 1:k
0373             <span class="keyword">if</span> m(i) &gt; 0
0374                 <span class="comment">% Separate out sorted coords for points in i'th cluster,</span>
0375                 <span class="comment">% and save values above and below median, component-wise</span>
0376                 Xsorted = reshape(Xsort(idx(Xord)==i), m(i), p);
0377                 nn = floor(.5*m(i));
0378                 <span class="keyword">if</span> mod(m(i),2) == 0
0379                     Xmid(i,:,1:2) = Xsorted([nn, nn+1],:)';
0380                 <span class="keyword">elseif</span> m(i) &gt; 1
0381                     Xmid(i,:,1:2) = Xsorted([nn, nn+2],:)';
0382                 <span class="keyword">else</span>
0383                     Xmid(i,:,1:2) = Xsorted([1, 1],:)';
0384                 <span class="keyword">end</span>
0385             <span class="keyword">end</span>
0386         <span class="keyword">end</span>
0387     <span class="keyword">case</span> <span class="string">'hamming'</span>
0388         Xsum = zeros(k,p);
0389         <span class="keyword">for</span> i = 1:k
0390             <span class="keyword">if</span> m(i) &gt; 0
0391                 <span class="comment">% Sum coords for points in i'th cluster, component-wise</span>
0392                 Xsum(i,:) = sum(X(idx==i,:), 1);
0393             <span class="keyword">end</span>
0394         <span class="keyword">end</span>
0395     <span class="keyword">end</span>
0396     
0397     <span class="comment">%</span>
0398     <span class="comment">% Begin phase two:  single reassignments</span>
0399     <span class="comment">%</span>
0400     changed = find(m' &gt; 0);
0401     lastmoved = 0;
0402     nummoved = 0;
0403     iter1 = iter;
0404     <span class="keyword">while</span> iter &lt; maxit
0405         <span class="comment">% Calculate distances to each cluster from each point, and the</span>
0406         <span class="comment">% potential change in total sum of errors for adding or removing</span>
0407         <span class="comment">% each point from each cluster.  Clusters that have not changed</span>
0408         <span class="comment">% membership need not be updated.</span>
0409         <span class="comment">%</span>
0410         <span class="comment">% Singleton clusters are a special case for the sum of dists</span>
0411         <span class="comment">% calculation.  Removing their only point is never best, so the</span>
0412         <span class="comment">% reassignment criterion had better guarantee that a singleton</span>
0413         <span class="comment">% point will stay in its own cluster.  Happily, we get</span>
0414         <span class="comment">% Del(i,idx(i)) == 0 automatically for them.</span>
0415         <span class="keyword">switch</span> distance
0416         <span class="keyword">case</span> <span class="string">'sqeuclidean'</span>
0417             <span class="keyword">for</span> i = changed
0418                 mbrs = (idx == i);
0419                 sgn = 1 - 2*mbrs; <span class="comment">% -1 for members, 1 for nonmembers</span>
0420                 <span class="keyword">if</span> m(i) == 1
0421                     sgn(mbrs) = 0; <span class="comment">% prevent divide-by-zero for singleton mbrs</span>
0422                 <span class="keyword">end</span>
0423                 Del(:,i) = (m(i) ./ (m(i) + sgn)) .* sum((X - C(repmat(i,n,1),:)).^2, 2);
0424             <span class="keyword">end</span>
0425         <span class="keyword">case</span> <span class="string">'cityblock'</span>
0426             <span class="keyword">for</span> i = changed
0427                 <span class="keyword">if</span> mod(m(i),2) == 0 <span class="comment">% this will never catch singleton clusters</span>
0428                     ldist = Xmid(repmat(i,n,1),:,1) - X;
0429                     rdist = X - Xmid(repmat(i,n,1),:,2);
0430                     mbrs = (idx == i);
0431                     sgn = repmat(1-2*mbrs, 1, p); <span class="comment">% -1 for members, 1 for nonmembers</span>
0432                     Del(:,i) = sum(max(0, max(sgn.*rdist, sgn.*ldist)), 2);
0433                 <span class="keyword">else</span>
0434                     Del(:,i) = sum(abs(X - C(repmat(i,n,1),:)), 2);
0435                 <span class="keyword">end</span>
0436             <span class="keyword">end</span>
0437         <span class="keyword">case</span> {<span class="string">'cosine'</span>,<span class="string">'correlation'</span>}
0438             <span class="comment">% The points are normalized, centroids are not, so normalize them</span>
0439             normC(changed) = sqrt(sum(C(changed,:).^2, 2));
0440             <span class="keyword">if</span> any(normC &lt; eps) <span class="comment">% small relative to unit-length data points</span>
0441                 error(sprintf(<span class="string">'Zero cluster centroid created at iteration %d.'</span>,iter));
0442             <span class="keyword">end</span>
0443             <span class="comment">% This can be done without a loop, but the loop saves memory allocations</span>
0444             <span class="keyword">for</span> i = changed
0445                 XCi = X * C(i,:)';
0446                 mbrs = (idx == i);
0447                 sgn = 1 - 2*mbrs; <span class="comment">% -1 for members, 1 for nonmembers</span>
0448                 Del(:,i) = 1 + sgn .*<span class="keyword">...</span>
0449                       (m(i).*normC(i) - sqrt((m(i).*normC(i)).^2 + 2.*sgn.*m(i).*XCi + 1));
0450             <span class="keyword">end</span>
0451         <span class="keyword">case</span> <span class="string">'hamming'</span>
0452             <span class="keyword">for</span> i = changed
0453                 <span class="keyword">if</span> mod(m(i),2) == 0 <span class="comment">% this will never catch singleton clusters</span>
0454                     <span class="comment">% coords with an unequal number of 0s and 1s have a</span>
0455                     <span class="comment">% different contribution than coords with an equal</span>
0456                     <span class="comment">% number</span>
0457                     unequal01 = find(2*Xsum(i,:) ~= m(i));
0458                     numequal01 = p - length(unequal01);
0459                     mbrs = (idx == i);
0460                     Di = abs(X(:,unequal01) - C(repmat(i,n,1),unequal01));
0461                     Del(:,i) = (sum(Di, 2) + mbrs*numequal01) / p;
0462                 <span class="keyword">else</span>
0463                     Del(:,i) = sum(abs(X - C(repmat(i,n,1),:)), 2) / p;
0464                 <span class="keyword">end</span>
0465             <span class="keyword">end</span>
0466         <span class="keyword">end</span>
0467 
0468         <span class="comment">% Determine best possible move, if any, for each point.  Next we</span>
0469         <span class="comment">% will pick one from those that actually did move.</span>
0470         previdx = idx;
0471         prevtotsumD = totsumD;
0472         [minDel, nidx] = min(Del, [], 2);
0473         moved = find(previdx ~= nidx);
0474         <span class="keyword">if</span> length(moved) &gt; 0
0475             <span class="comment">% Resolve ties in favor of not moving</span>
0476             moved = moved(Del((previdx(moved)-1)*n + moved) &gt; minDel(moved));
0477         <span class="keyword">end</span>
0478         <span class="keyword">if</span> length(moved) == 0
0479             <span class="comment">% Count an iteration if phase 2 did nothing at all, or if we're</span>
0480             <span class="comment">% in the middle of a pass through all the points</span>
0481             <span class="keyword">if</span> (iter - iter1) == 0 | nummoved &gt; 0
0482                 iter = iter + 1;
0483                 <span class="keyword">if</span> display &gt; 2 <span class="comment">% 'iter'</span>
0484                     disp(sprintf(dispfmt,iter,2,nummoved,totsumD));
0485                 <span class="keyword">end</span>
0486             <span class="keyword">end</span>
0487             converged = true;
0488             <span class="keyword">break</span>;
0489         <span class="keyword">end</span>
0490         
0491         <span class="comment">% Pick the next move in cyclic order</span>
0492         moved = mod(min(mod(moved - lastmoved - 1, n) + lastmoved), n) + 1;
0493         
0494         <span class="comment">% If we've gone once through all the points, that's an iteration</span>
0495         <span class="keyword">if</span> moved &lt;= lastmoved
0496             iter = iter + 1;
0497             <span class="keyword">if</span> display &gt; 2 <span class="comment">% 'iter'</span>
0498                 disp(sprintf(dispfmt,iter,2,nummoved,totsumD));
0499             <span class="keyword">end</span>
0500             <span class="keyword">if</span> iter &gt;= maxit, <span class="keyword">break</span>; <span class="keyword">end</span>
0501             nummoved = 0;
0502         <span class="keyword">end</span>
0503         nummoved = nummoved + 1;
0504         lastmoved = moved;
0505         
0506         oidx = idx(moved);
0507         nidx = nidx(moved);
0508         totsumD = totsumD + Del(moved,nidx) - Del(moved,oidx);
0509         
0510         <span class="comment">% Update the cluster index vector, and rhe old and new cluster</span>
0511         <span class="comment">% counts and centroids</span>
0512         idx(moved) = nidx;
0513         m(nidx) = m(nidx) + 1;
0514         m(oidx) = m(oidx) - 1;
0515         <span class="keyword">switch</span> distance
0516         <span class="keyword">case</span> <span class="string">'sqeuclidean'</span>
0517             C(nidx,:) = C(nidx,:) + (X(moved,:) - C(nidx,:)) / m(nidx);
0518             C(oidx,:) = C(oidx,:) - (X(moved,:) - C(oidx,:)) / m(oidx);
0519         <span class="keyword">case</span> <span class="string">'cityblock'</span>
0520             <span class="keyword">for</span> i = [oidx nidx]
0521                 <span class="comment">% Separate out sorted coords for points in each cluster.</span>
0522                 <span class="comment">% New centroid is the coord median, save values above and</span>
0523                 <span class="comment">% below median.  All done component-wise.</span>
0524                 Xsorted = reshape(Xsort(idx(Xord)==i), m(i), p);
0525                 nn = floor(.5*m(i));
0526                 <span class="keyword">if</span> mod(m(i),2) == 0
0527                     C(i,:) = .5 * (Xsorted(nn,:) + Xsorted(nn+1,:));
0528                     Xmid(i,:,1:2) = Xsorted([nn, nn+1],:)';
0529                 <span class="keyword">else</span>
0530                     C(i,:) = Xsorted(nn+1,:);
0531                     <span class="keyword">if</span> m(i) &gt; 1
0532                         Xmid(i,:,1:2) = Xsorted([nn, nn+2],:)';
0533                     <span class="keyword">else</span>
0534                         Xmid(i,:,1:2) = Xsorted([1, 1],:)';
0535                     <span class="keyword">end</span>
0536                 <span class="keyword">end</span>
0537             <span class="keyword">end</span>
0538         <span class="keyword">case</span> {<span class="string">'cosine'</span>,<span class="string">'correlation'</span>}
0539             C(nidx,:) = C(nidx,:) + (X(moved,:) - C(nidx,:)) / m(nidx);
0540             C(oidx,:) = C(oidx,:) - (X(moved,:) - C(oidx,:)) / m(oidx);
0541         <span class="keyword">case</span> <span class="string">'hamming'</span>
0542             <span class="comment">% Update summed coords for points in each cluster.  New</span>
0543             <span class="comment">% centroid is the coord median.  All done component-wise.</span>
0544             Xsum(nidx,:) = Xsum(nidx,:) + X(moved,:);
0545             Xsum(oidx,:) = Xsum(oidx,:) - X(moved,:);
0546             C(nidx,:) = .5*sign(2*Xsum(nidx,:) - m(nidx)) + .5;
0547             C(oidx,:) = .5*sign(2*Xsum(oidx,:) - m(oidx)) + .5;
0548         <span class="keyword">end</span>
0549         changed = sort([oidx nidx]);
0550     <span class="keyword">end</span> <span class="comment">% phase two</span>
0551     
0552     <span class="keyword">if</span> (~converged) &amp; (display &gt; 0)
0553         warning(sprintf(<span class="string">'Failed to converge in %d iterations.'</span>, maxit));
0554     <span class="keyword">end</span>
0555 
0556     <span class="comment">% Calculate cluster-wise sums of distances</span>
0557     nonempties = find(m(:)'&gt;0);
0558     D(:,nonempties) = <a href="#_sub1" class="code" title="subfunction D = distfun(X, C, dist, iter)">distfun</a>(X, C(nonempties,:), distance, iter);
0559     d = D((idx-1)*n + (1:n)');
0560     sumD = zeros(k,1);
0561     <span class="keyword">for</span> i = 1:k
0562         sumD(i) = sum(d(idx == i));
0563     <span class="keyword">end</span>
0564     <span class="keyword">if</span> display &gt; 1 <span class="comment">% 'final' or 'iter'</span>
0565         disp(sprintf(<span class="string">'%d iterations, total sum of distances = %g'</span>,iter,totsumD));
0566     <span class="keyword">end</span>
0567 
0568     <span class="comment">% Save the best solution so far</span>
0569     <span class="keyword">if</span> totsumD &lt; totsumDBest
0570         totsumDBest = totsumD;
0571         idxBest = idx;
0572         Cbest = C;
0573         sumDBest = sumD;
0574         <span class="keyword">if</span> nargout &gt; 3
0575             Dbest = D;
0576         <span class="keyword">end</span>
0577     <span class="keyword">end</span>
0578 <span class="keyword">end</span>
0579 
0580 <span class="comment">% Return the best solution</span>
0581 idx = idxBest;
0582 C = Cbest;
0583 sumD = sumDBest;
0584 <span class="keyword">if</span> nargout &gt; 3
0585     D = Dbest;
0586 <span class="keyword">end</span>
0587 
0588 
0589 <span class="comment">%------------------------------------------------------------------</span>
0590 
0591 <a name="_sub1" href="#_subfunctions" class="code">function D = distfun(X, C, dist, iter)</a>
0592 <span class="comment">%DISTFUN Calculate point to cluster centroid distances.</span>
0593 [n,p] = size(X);
0594 D = zeros(n,size(C,1));
0595 clusts = 1:size(C,1);
0596 
0597 <span class="keyword">switch</span> dist
0598 <span class="keyword">case</span> <span class="string">'sqeuclidean'</span>
0599     <span class="keyword">for</span> i = clusts
0600         D(:,i) = sum((X - C(repmat(i,n,1),:)).^2, 2);
0601     <span class="keyword">end</span>
0602 <span class="keyword">case</span> <span class="string">'cityblock'</span>
0603     <span class="keyword">for</span> i = clusts
0604         D(:,i) = sum(abs(X - C(repmat(i,n,1),:)), 2);
0605     <span class="keyword">end</span>
0606 <span class="keyword">case</span> {<span class="string">'cosine'</span>,<span class="string">'correlation'</span>}
0607     <span class="comment">% The points are normalized, centroids are not, so normalize them</span>
0608     normC = sqrt(sum(C.^2, 2));
0609     <span class="keyword">if</span> any(normC &lt; eps) <span class="comment">% small relative to unit-length data points</span>
0610         error(sprintf(<span class="string">'Zero cluster centroid created at iteration %d.'</span>,iter));
0611     <span class="keyword">end</span>
0612     <span class="comment">% This can be done without a loop, but the loop saves memory allocations</span>
0613     <span class="keyword">for</span> i = clusts
0614         D(:,i) = 1 - (X * C(i,:)') ./ normC(i);
0615     <span class="keyword">end</span>
0616 <span class="keyword">case</span> <span class="string">'hamming'</span>
0617     <span class="keyword">for</span> i = clusts
0618         D(:,i) = sum(abs(X - C(repmat(i,n,1),:)), 2) / p;
0619     <span class="keyword">end</span>
0620 <span class="keyword">end</span>
0621 
0622 
0623 <span class="comment">%------------------------------------------------------------------</span>
0624 
0625 <a name="_sub2" href="#_subfunctions" class="code">function [centroids, counts] = gcentroids(X, index, clusts, dist, Xsort, Xord)</a>
0626 <span class="comment">%GCENTROIDS Centroids and counts stratified by group.</span>
0627 [n,p] = size(X);
0628 num = length(clusts);
0629 centroids = repmat(NaN, [num p]);
0630 counts = zeros(num,1);
0631 <span class="keyword">for</span> i = 1:num
0632     members = find(index == clusts(i));
0633     <span class="keyword">if</span> length(members) &gt; 0
0634         counts(i) = length(members);
0635         <span class="keyword">switch</span> dist
0636         <span class="keyword">case</span> <span class="string">'sqeuclidean'</span>
0637             centroids(i,:) = sum(X(members,:),1) / counts(i);
0638         <span class="keyword">case</span> <span class="string">'cityblock'</span>
0639             <span class="comment">% Separate out sorted coords for points in i'th cluster,</span>
0640             <span class="comment">% and use to compute a fast median, component-wise</span>
0641             Xsorted = reshape(Xsort(index(Xord)==clusts(i)), counts(i), p);
0642             nn = floor(.5*counts(i));
0643             <span class="keyword">if</span> mod(counts(i),2) == 0
0644                 centroids(i,:) = .5 * (Xsorted(nn,:) + Xsorted(nn+1,:));
0645             <span class="keyword">else</span>
0646                 centroids(i,:) = Xsorted(nn+1,:);
0647             <span class="keyword">end</span>
0648         <span class="keyword">case</span> {<span class="string">'cosine'</span>,<span class="string">'correlation'</span>}
0649             centroids(i,:) = sum(X(members,:),1) / counts(i); <span class="comment">% unnormalized</span>
0650         <span class="keyword">case</span> <span class="string">'hamming'</span>
0651             <span class="comment">% Compute a fast median for binary data, component-wise</span>
0652             centroids(i,:) = .5*sign(2*sum(X(members,:), 1) - counts(i)) + .5;
0653         <span class="keyword">end</span>
0654     <span class="keyword">end</span>
0655 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Wed 28-Jul-2021 14:15:23 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" target="_parent">m2html</a></strong> &copy; 2005</address>
</body>
</html>